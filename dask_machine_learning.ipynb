{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "dask_machine_learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gaukhar-ai/for_my_Thinkful_work/blob/master/dask_machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei_f9si-O407"
      },
      "source": [
        "# Solutions to checkpoint 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7CiAxgJO408"
      },
      "source": [
        "In the following task, you'll continue working with the [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud/download) dataset from Kaggle. Before moving on to the tasks, you should load the dataset using Dask.\n",
        "\n",
        "Please submit your solutions to the following tasks as a link to your jupyter notebook on Github."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU-mySrDPLZy"
      },
      "source": [
        "#!pip install dask-ml --upgrade"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5_eRYJxO408"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate, GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import joblib\n",
        "from dask.distributed import Client, progress\n",
        "from dask_ml.model_selection import train_test_split\n",
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_vcN2siO40_",
        "outputId": "5ddb3e94-0d5d-420b-cefb-a8c371ff5d61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "client = Client(n_workers=4, threads_per_worker=2, memory_limit='2GB')\n",
        "client"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table style=\"border: 2px solid white;\">\n",
              "<tr>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3 style=\"text-align: left;\">Client</h3>\n",
              "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
              "  <li><b>Scheduler: </b>tcp://127.0.0.1:36119</li>\n",
              "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
              "</ul>\n",
              "</td>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3 style=\"text-align: left;\">Cluster</h3>\n",
              "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
              "  <li><b>Workers: </b>4</li>\n",
              "  <li><b>Cores: </b>8</li>\n",
              "  <li><b>Memory: </b>8.00 GB</li>\n",
              "</ul>\n",
              "</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<Client: 'tcp://127.0.0.1:36119' processes=4 threads=8, memory=8.00 GB>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzkOM4gbO41C"
      },
      "source": [
        "# This loads the data into Dask dataframe\n",
        "df = dd.read_csv('https://www.kaggle.com/mlg-ulb/creditcardfraud.csv', dtype={'Time': 'float64'})\n",
        "\n",
        "#the data is too big to commit to my repo. tried to copy the path and other solutions but not working still, shoul research more this. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRuHY0cJO41F"
      },
      "source": [
        "## 1. In this task, you'll train several machine learning models from scikit-learn using Dask as the backend of joblib. This time, you need to use all the variables except `Class` as your feature set. `Class` variable will be your target variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emrmagaeO41F"
      },
      "source": [
        "# This is our feature set\n",
        "X = df.drop(\"Class\", axis=1)\n",
        "\n",
        "# This is our target variable\n",
        "Y = df[\"Class\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "# Since our data can fit into memory\n",
        "# we persist them to the RAM.\n",
        "X_train.persist()\n",
        "X_test.persist()\n",
        "y_train.persist()\n",
        "y_test.persist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVt8FJDYO41I"
      },
      "source": [
        "lr = LogisticRegression()\n",
        "\n",
        "with joblib.parallel_backend('dask'):\n",
        "    lr.fit(X_train.compute(), y_train.compute())\n",
        "    \n",
        "preds_train = lr.predict(X_train.values.compute())\n",
        "preds_test = lr.predict(X_test.values.compute())\n",
        "\n",
        "print(\"Logistic regression training score is: \", roc_auc_score(preds_train, y_train.values.compute()))\n",
        "print(\"Logistic regression test score is: \", roc_auc_score(preds_test, y_test.values.compute()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF8MKTQwO41K"
      },
      "source": [
        "gbc = GradientBoostingClassifier()\n",
        "\n",
        "with joblib.parallel_backend('dask'):\n",
        "    gbc.fit(X_train.compute(), y_train.compute())\n",
        "    \n",
        "preds_train = gbc.predict(X_train.values.compute())\n",
        "preds_test = gbc.predict(X_test.values.compute())\n",
        "\n",
        "print(\"Gradient boosting tree training score is: \", roc_auc_score(preds_train, y_train.values.compute()))\n",
        "print(\"Gradient boosting tree test score is: \", roc_auc_score(preds_test, y_test.values.compute()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opzxil0ZO41N"
      },
      "source": [
        "rfc = RandomForestClassifier()\n",
        "\n",
        "with joblib.parallel_backend('dask'):\n",
        "    rfc.fit(X_train.compute(), y_train.compute())\n",
        "    \n",
        "preds_train = rfc.predict(X_train.values.compute())\n",
        "preds_test = rfc.predict(X_test.values.compute())\n",
        "\n",
        "print(\"Random forest training score is: \", roc_auc_score(preds_train, y_train.values.compute()))\n",
        "print(\"Random forest test score is: \", roc_auc_score(preds_test, y_test.values.compute()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USbgU9B6O41Q"
      },
      "source": [
        "## 2. Compare the results of your models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrur3QbAO41Q"
      },
      "source": [
        "According to the results, the best performing model is the random forest. It's performance in both training and test sets are higher than those of the logistic regression and gradient boosting tree. However, we should note that we run these models using their default parameters. Ideally, one should do hyperparameter tuning by doing something like grid search or random search."
      ]
    }
  ]
}