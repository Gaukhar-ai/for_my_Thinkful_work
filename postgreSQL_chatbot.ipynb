{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "postgreSQL.chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gaukhar-ai/for_my_Thinkful_work/blob/master/postgreSQL_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNqdLwvisRR0"
      },
      "source": [
        "# Solutions to Checkpoint 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Wax_Mm1sRR1"
      },
      "source": [
        "## 1. First, make some data preprocessing to clean up the data. You can use your solution to the assignment of the data preprocessing checkpoint of this module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zITt04QTsRR2",
        "outputId": "1efc7751-1d5b-4c7f-fd5c-ec2d63048105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "import nltk\n",
        "import spacy\n",
        "import re\n",
        "from chatterbot import ChatBot\n",
        "from chatterbot.trainers import ListTrainer, ChatterBotCorpusTrainer\n",
        "from chatterbot.conversation import Statement\n",
        "import random\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\")\n",
        "\n",
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC7JfFS_sRR6"
      },
      "source": [
        "postgres_user = 'dsbc_student'\n",
        "postgres_pw = '7*.8G9QH21'\n",
        "postgres_host = '142.93.121.174'\n",
        "postgres_port = '5432'\n",
        "postgres_db = 'cornell_movie_dialogs'\n",
        "\n",
        "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
        "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
        "\n",
        "dialogs_df = pd.read_sql_query('select * from dialogs',con=engine)\n",
        "\n",
        "# no need for an open connection, as we're only doing a single query\n",
        "engine.dispose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T5fAceNsRR9"
      },
      "source": [
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
        "\n",
        "# below is necessary to avoid memory error of SpaCy\n",
        "nlp.max_length = 20000000\n",
        "\n",
        "# all the processing work is done below, so it may take a while\n",
        "dialogs_doc = nlp(\" \".join(dialogs_df.dialogs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF8t4ngFuUHk"
      },
      "source": [
        "dialog_sents = [sent.text for sent in dialogs_doc.sents if len(sent.text) > 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nGE_yOlsRSG"
      },
      "source": [
        "## 2. Develop a chatbot using this corpus. In doing this, you're free to choose a chatbot development libary like ChatterBot or to write your own code from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN3M5hZW53tI"
      },
      "source": [
        "GREETING_INPUTS = [\"hello\", \"hi\", \"greetings\", \"what's up\",\"hey\"]\n",
        "GREETING_RESPONSES = [\"hello\", \"hi\", \"hey\", \"hi there\"]\n",
        "def greeting(sentence):\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikUbA7qMsRSI",
        "outputId": "2ecde1b9-d500-451f-a264-b662f01b13ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# create a chatbot\n",
        "chatbot = ChatBot('Dialogs')\n",
        "# this is to remove the accumulated knowledge base\n",
        "chatbot.storage.drop()\n",
        "\n",
        "# create a new trainer for the chatbot\n",
        "trainer = ListTrainer(chatbot)\n",
        "\n",
        "# train the chatbot\n",
        "trainer.train(dialog_sents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "List Trainer: [####################] 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfUp0RgqsRSM"
      },
      "source": [
        "## 3. Make a conversation with your chatbot and discuss the strengths and weaknesses of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQsVqbUy6DTB"
      },
      "source": [
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9RsdAEssRSN",
        "scrolled": true,
        "outputId": "58a3df86-1ad7-45bc-e21c-666aacefe17a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "print(\"Cornell: I will try to respond you reasonably. If you want to exit, type bye please.\")\n",
        "\n",
        "# below is the chatting\n",
        "while True:\n",
        "    \n",
        "    user_input = input(\"User: \")\n",
        "    user_input=user_input.lower()\n",
        "    \n",
        "    if(user_input!='bye'):\n",
        "        if(user_input == 'thanks' or user_input == 'thank you'):\n",
        "            break\n",
        "            print(\"Cornell: You're welcome.\")\n",
        "        else:\n",
        "            if(greeting(user_input) != None):\n",
        "                print(\"Cornell: \" + greeting(user_input))\n",
        "            else:\n",
        "                print(\"Cornell: \", end = \"\")\n",
        "                print(chatbot.get_response(user_input))\n",
        "    else:\n",
        "        print(\"Cornell: Bye! It was a great chat.\")\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cornell: I will try to respond you reasonably. If you want to exit, type bye please.\n",
            "User: Hello\n",
            "Cornell: hello\n",
            "User: Do you enjoy watching movies?\n",
            "Cornell: Made me sick, but what did I care?\n",
            "User: Oh! Well, how are you then?\n",
            "Cornell: I just struck it rich... I think we can do a little business.\n",
            "User: What kind of business?\n",
            "Cornell: Black market art.\n",
            "User: Oh no. I prefer talking about movies.\n",
            "Cornell: Why?\n",
            "User: Because, I'm kind of a descent person and like to respect the rule of law.\n",
            "Cornell: Who?\n",
            "User: Me.\n",
            "Cornell: This endless ...blonde babble.\n",
            "User: Anyway, do you know something about technology?\n",
            "Cornell: I believe we share an art instructor Have fun tonight?\n",
            "User: No. What about artificial intelligence?\n",
            "Cornell: Something, apperently, of an unknown origin.\n",
            "User: Definitely.\n",
            "Cornell: I heard what happened.\n",
            "User: What happened?\n",
            "Cornell: We and my pal here have been taking it on the chin for the last few hours... You real down?\n",
            "User: Hmm, I think I need to go now.\n",
            "Cornell: Well, no... Then that's all you had to say.\n",
            "User: Yes, sorry. I need to work on my natural language processing homework.\n",
            "Cornell: Wow Let's go.\n",
            "User: Do you also enjoy natural language processing?\n",
            "Cornell: I heard enough of it in school!\n",
            "User: That's great!\n",
            "Cornell: If not, speak now.\n",
            "User: Sorry but I have to go.\n",
            "Cornell: Well, no... Then that's all you had to say.\n",
            "User: Yes. Bye!\n",
            "Cornell: Bastard.\n",
            "User: I wasn't expecting this.\n",
            "Cornell: He owes me money... I hear you've got visitors.\n",
            "User: No.\n",
            "Cornell: I found a picture of Jared Leto in one of her drawers, so I'm pretty sure she's not harboring same-sex tendencies.\n",
            "User: Bye\n",
            "Cornell: Bye! It was a great chat.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtdnrUBaUt4U"
      },
      "source": [
        "Not bad, right? We can really hear the Hollywood jargon in the conversation. As expected, our bot carries the colors and the biases in the movies!"
      ]
    }
  ]
}