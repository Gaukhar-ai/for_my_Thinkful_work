{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stopwords,wordnet,punkt,getenberg.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gaukhar-ai/for_my_Thinkful_work/blob/master/stopwords%2Cwordnet%2Cpunkt%2Cgetenberg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1OtXGW9qYN_",
        "outputId": "0e12cae5-2f0e-4f9d-9ec4-c238f8b58dba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('gutenberg')\n",
        "\n",
        "from nltk.corpus import gutenberg"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTb2s10Oqds9"
      },
      "source": [
        "docs = [gutenberg.raw(fileid) for fileid in gutenberg.fileids()]\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkSkt9VBy_gA"
      },
      "source": [
        "book_length = [len(doc) for doc in docs]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvEyYoB8zAXX",
        "outputId": "dea41161-d479-4710-af24-485456a1948b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "book_length"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[887071,\n",
              " 466292,\n",
              " 673022,\n",
              " 4332554,\n",
              " 38153,\n",
              " 249439,\n",
              " 84663,\n",
              " 144395,\n",
              " 457450,\n",
              " 406629,\n",
              " 320525,\n",
              " 935158,\n",
              " 1242990,\n",
              " 468220,\n",
              " 112310,\n",
              " 162881,\n",
              " 100351,\n",
              " 711215]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PlDr22EqfJ2",
        "outputId": "dcf005b0-ca49-431b-88ed-c8686d8ce86c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gutenberg.fileids()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NRKGVCZyXAR"
      },
      "source": [
        "from gensim.summarization import summarize\n",
        "\n",
        "summarize(gutenberg.raw(\"milton-paradise.txt\"), word_count=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k39jbreYyttz"
      },
      "source": [
        "summary = summarize(gutenberg.raw(\"whitman-leaves.txt\"), word_count=200)\n",
        "print(summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-h3rF0tzFOR"
      },
      "source": [
        "doc = gutenberg.raw(\"shakespeare-caesar.txt\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7WSp6dM1T8O"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sents = sent_tokenize(doc)\n",
        "sents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez-fiPxC1jXl"
      },
      "source": [
        "# !pip install markovify --quiet\n",
        "import markovify\n",
        "\n",
        "model = markovify.Text(sents, state_size=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKMidHwR2Mau"
      },
      "source": [
        "sentence_list = []\n",
        "while len(sentence_list) <=5:\n",
        "  \n",
        "  sentence = model.make_short_sentence(max_chars=100, min_chars=30, tries=100)\n",
        "  if sentence not in sentence_list:\n",
        "    sentence_list.append(sentence)\n",
        "    print(sentence)\n",
        "    print('-----------------')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgOVqCF72X4e"
      },
      "source": [
        "import markovify\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "class POSifiedText(markovify.Text):\n",
        "    def word_split(self, sentence):\n",
        "        words = re.split(self.word_split_pattern, sentence)\n",
        "        words = [ \"::\".join(tag) for tag in nltk.pos_tag(words) ]\n",
        "        return words\n",
        "\n",
        "    def word_join(self, words):\n",
        "        sentence = \" \".join(word.split(\"::\")[0] for word in words)\n",
        "        return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y5E_AL14LC3"
      },
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5r5WfkM4AvS"
      },
      "source": [
        "model = POSifiedText(sents, state_size=4)\n",
        "\n",
        "sentence_list = []\n",
        "while len(sentence_list) <=5:\n",
        "  \n",
        "  sentence = model.make_short_sentence(max_chars=100, min_chars=30, tries=100)\n",
        "  if sentence not in sentence_list:\n",
        "    sentence_list.append(sentence)\n",
        "    print(sentence)\n",
        "    print('-----------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxnHmswl4IsP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}