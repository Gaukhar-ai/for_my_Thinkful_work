{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alice.in.wonderland.book.token.count.lemma.frequency.headings,spaces.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOqa7qyhmastzq6tydEiqmZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gaukhar-ai/for_my_Thinkful_work/blob/master/alice_in_wonderland_book_token_count_lemma_frequency_headings%2Cspaces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzyyDYMbMpGz"
      },
      "source": [
        "from collections import Counter\n",
        "import nltk\n",
        "import spacy\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzkGXAz-YcQW"
      },
      "source": [
        "nltk.download('gutenberg')\n",
        "\n",
        "#!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A2uhbAWbMgE",
        "outputId": "c53f1683-3f63-4e5b-987d-c6c5e0ac2a32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.corpus import gutenberg\n",
        "\n",
        "#grab and process the raw data\n",
        "print(gutenberg.fileids())\n",
        "\n",
        "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
        "alice = gutenberg.raw('carroll-alice.txt')\n",
        "\n",
        "#print the first 100 characters of Alice\n",
        "print('\\nRaw:\\n', alice[0:100])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n",
            "\n",
            "Raw:\n",
            " [Alice's Adventures in Wonderland by Lewis Carroll 1865]\n",
            "\n",
            "CHAPTER I. Down the Rabbit-Hole\n",
            "\n",
            "Alice was\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekLxnvDebW9G"
      },
      "source": [
        "#pattern matches all text between square brackets"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi-JCb6lcnTy",
        "outputId": "ecc24726-4cff-4dcd-8428-8bf71515e11a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pattern = '[\\[].*?[\\]]'\n",
        "persuasion = re.sub(pattern, '', persuasion)\n",
        "alice = re.sub(pattern, '', alice)\n",
        "\n",
        "#print the 100 first characters of Alice again:\n",
        "print('Title removed:', alice[0:100]) \n",
        "print('Title removed:', persuasion[0:100]) "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title removed: \n",
            "\n",
            "\n",
            "\n",
            "Alice was beginning to get very tired of sitting by her sister on the\n",
            "bank, and of having nothin\n",
            "Title removed: \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Sir Walter Elliot, of Kellynch Hall, in Somersetshire, was a man who,\n",
            "for his own amusement, n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUrZUetWcnXN",
        "outputId": "a12d0a4c-7f3e-4255-9d8f-8a66f1590216",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#match and remove chapter headings:\n",
        "persuasion = re.sub(r'Chapter .*', '', persuasion)\n",
        "alice = re.sub(r'CHAPTER .*', '', alice)\n",
        "\n",
        "print('Chapter headings removed:', alice[0:100])\n",
        "print('Chapter headings removed:', persuasion[0:100])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chapter headings removed: \n",
            "\n",
            "\n",
            "\n",
            "Alice was beginning to get very tired of sitting by her sister on the\n",
            "bank, and of having nothin\n",
            "Chapter headings removed: \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Sir Walter Elliot, of Kellynch Hall, in Somersetshire, was a man who,\n",
            "for his own amusement, n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MREXoaxcnZ7",
        "outputId": "426025fc-b027-44fb-9e6b-9298d2027ad3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#remove newlines and other extra whitespace by splitting and rejoining\n",
        "persuasion = ' '.join(persuasion.split())\n",
        "alice = ' '.join(alice.split())\n",
        "\n",
        "print('Extra whitespace removed:', alice[0:100])\n",
        "print('Title removed:', alice[0:100]) "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extra whitespace removed: Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to\n",
            "Title removed: Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5KpoYPIcndT"
      },
      "source": [
        "\n",
        "#TOKENIZATION:\n",
        "#each individual meaningful piece from a text is a token and the process of breaking up the text into these peices is called tokenization"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-jcdw_0cngH"
      },
      "source": [
        "nlp = spacy.load('en')\n",
        "\n",
        "#processing work\n",
        "alice_doc = nlp(alice)\n",
        "persuasion_doc = nlp(persuasion)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aUuyFo_cni_"
      },
      "source": [
        "#explore the objects built"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5IYrXf5cnmV",
        "outputId": "f5fe5874-5da0-40c3-8fca-4fd73983b1da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('The alice_doc object is a {} object.'.format(type(alice_doc)))\n",
        "print('It is {} tokens long'.format(len(alice_doc)))\n",
        "print(\"The first three tokens are '{}'\".format(alice_doc[:3]))\n",
        "print('The type of each token is {}'. format(type(alice_doc[0])))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The alice_doc object is a <class 'spacy.tokens.doc.Doc'> object.\n",
            "It is 34408 tokens long\n",
            "The first three tokens are 'Alice was beginning'\n",
            "The type of each token is <class 'spacy.tokens.token.Token'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jmWMIrccnpu"
      },
      "source": [
        "#remove stop words with spacy:"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXlQr8tYcns6"
      },
      "source": [
        "alice_without_stopwords = [token for token in alice_doc if not token.is_stop]\n",
        "persuasion_without_stopwords = [token for token in persuasion_doc if not token.is_stop]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGJKHIFhcnvR"
      },
      "source": [
        "#UTILITY FUNCTION TO CALCULATE HOW FREQUENTLY WORDS APPEAR IN THE TEXT:"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v2eBRcicnyb"
      },
      "source": [
        "def word_frequencies(text):\n",
        "\n",
        "#build a list of words, strip out punctuation:\n",
        "  words = []\n",
        "  for token in text:\n",
        "    if not token.is_punct:\n",
        "      words.append(token.text)\n",
        "#build and return a 'Counter' object containing word counts \n",
        "  return Counter(words)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7LeXjRTcn1n",
        "outputId": "acfe34ea-6815-4997-ef4c-7de6c127a736",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#instantiate the list of the most common words\n",
        "alice_word_freq = word_frequencies(alice_without_stopwords).most_common(10)\n",
        "persuasion_word_freq = word_frequencies(persuasion_without_stopwords).most_common(10)\n",
        "print('\\nAlice:', alice_word_freq)\n",
        "print('Persuasion:', persuasion_word_freq)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Alice: [('said', 453), ('Alice', 394), ('little', 124), ('like', 84), ('went', 83), ('know', 83), ('thought', 74), ('Queen', 73), ('time', 68), ('King', 61)]\n",
            "Persuasion: [('Anne', 496), ('Captain', 297), ('Mrs', 291), ('Elliot', 288), ('Mr', 254), ('Wentworth', 217), ('Lady', 191), ('good', 181), ('little', 175), ('Charles', 166)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1ebdsj4cn42"
      },
      "source": [
        "#LEMMATIZATION: think, thouth, thinking = think is the stem"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYdOZuUkcn8T"
      },
      "source": [
        "#UTILITY FUNCTION TO CALCULATE HOW FREQUENTLY EACH LEMMA APPEARS IN THE TEXT"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzJ66EWKbW_x",
        "outputId": "d39b25d2-dd22-4e35-e500-bb2c7c188b05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def lemma_frequencies(text):\n",
        "  #build a list of lemmas, strip out punctuation\n",
        "  lemmas = []\n",
        "  for token in text:\n",
        "    if not token.is_punct:\n",
        "      lemmas.append(token.lemma_)\n",
        "\n",
        "      #build and return a 'Counter' object containing lemma counts \n",
        "  return Counter(lemmas)\n",
        "\n",
        "#instantiate your list of most common lemmas\n",
        "alice_lemma_freq = lemma_frequencies(alice_without_stopwords).most_common(10)\n",
        "persuasion_lemma_freq = lemma_frequencies(persuasion_without_stopwords).most_common(10)\n",
        "print('\\nAlice:', alice_lemma_freq)\n",
        "print('Persuasion:', persuasion_lemma_freq)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Alice: [('say', 476), ('Alice', 394), ('think', 130), ('go', 130), ('little', 124), ('look', 105), ('know', 103), ('come', 96), ('like', 92), ('begin', 91)]\n",
            "Persuasion: [('Anne', 496), ('Captain', 297), ('Mrs', 291), ('Elliot', 288), ('think', 258), ('Mr', 254), ('know', 252), ('good', 222), ('Wentworth', 215), ('Lady', 191)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC5rRmXibXCV",
        "outputId": "34833844-b535-49b6-9f87-f89e42953e0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "alice_lemma_common = [pair[0] for pair in alice_lemma_freq]\n",
        "persuasion_lemma_common = [pair[0] for pair in persuasion_lemma_freq]\n",
        "print('Unique to Alice:', set(alice_lemma_common) - set(persuasion_lemma_common))\n",
        "print('Unique to Persuasion:', set(persuasion_lemma_common) - set(alice_lemma_freq))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique to Alice: {'say', 'little', 'go', 'like', 'look', 'come', 'Alice', 'begin'}\n",
            "Unique to Persuasion: {'know', 'good', 'Lady', 'Captain', 'Mrs', 'Elliot', 'think', 'Wentworth', 'Mr', 'Anne'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8nK_5-XbXE0",
        "outputId": "ee4fdd28-3989-4471-e0ca-8fb03a202cde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#initial exploration of sentences\n",
        "sentences = list(alice_doc.sents)\n",
        "print('Alice in Wonderland has {} sentences.'.format(len(sentences)))\n",
        "\n",
        "example_sentence = [2]\n",
        "print('Here is an example: \\n{}\\n'.format(example_sentence))\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alice in Wonderland has 1989 sentences.\n",
            "Here is an example: \n",
            "[2]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcgIsqo2bXHt"
      },
      "source": [
        "#doc.sents gives each sentence as a span ojbect. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05aNWY1LbXKd"
      },
      "source": [
        "#some metrics around the sentence:\n",
        "example_words = [token for token in example_sentence if not token.is_punct]\n",
        "unique_words = set([token.text for token in example_words])\n",
        "\n",
        "print((\"There are {} words in this sentence, and {} of them are\"\"unique.\").format(len(example_words), len(unique_words)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnAdSz-8bXNV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNO4KyVqbXQg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}